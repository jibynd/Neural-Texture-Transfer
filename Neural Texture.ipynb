{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Texture Transfer\n",
        "<img src='items/Titre.jpg' alt=\"Drawing\" style=\"width: 200px\"/>"
      ],
      "metadata": {
        "id": "1zGG89oiH5eR",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (16,20)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import scipy.misc\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "kp_image = kp_image.img_to_array\n",
        "from ntUtils import *\n",
        "import IPython.display"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "vQKTnlOxH2Pq",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Preprocessing\n",
        "\n",
        "* Slicer takes an image and splits it into pieces according to the parameter split. \n",
        "* Recomp is the corresponding inverse function"
      ],
      "metadata": {
        "id": "qm4yoaS9gWu8",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def slicer(path_to_img,  split = (2,2), mode = None, size = None):\n",
        "    img = Image.open(path_to_img)\n",
        "    if mode == 'texture':\n",
        "        img = img.resize(size)\n",
        "    imgwidth, imgheight = img.size\n",
        "    n_split_w, n_split_h = split\n",
        "    height = imgheight//n_split_h; width = imgwidth//n_split_w\n",
        "    \n",
        "    imgs = []\n",
        "    for i in range(0,n_split_h*height,height):\n",
        "        for j in range(0,n_split_w*width,width):\n",
        "            box = (j, i, j+width, i+height)\n",
        "            x = img.crop(box)\n",
        "            imgs.append(kp_image(x))\n",
        "    return tf.constant(imgs, dtype='uint8')\n",
        "  \n",
        " \n",
        "def recomp(img, split=(2,2)):\n",
        "    def concat(arr, axis):\n",
        "        if len(arr) > 1:\n",
        "            return np.concatenate(arr, axis = axis)\n",
        "        else:\n",
        "            return arr\n",
        "    n_split_w, n_split_h = split\n",
        "    imgs = []\n",
        "    for i in range(n_split_h):\n",
        "        imgs.append(concat(img[i*n_split_w:(i+1)*n_split_w], axis = 1))\n",
        "    tout = concat(imgs, axis = 0)\n",
        "    image = Image.fromarray(tout)\n",
        "    return image"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "8Esal5hdIJxl",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute Features\n",
        "\n",
        "* gram_matrix calculates the correlation of texture features for a batch of pictures\n",
        "* get_deep_outputs computes some features for the content and texture"
      ],
      "metadata": {
        "id": "n1brlYcQkUnq",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_matrix(input_tensor):\n",
        "    batch,  height, width, channels = [int(d) for d in input_tensor.shape]\n",
        "    tensor = tf.reshape(input_tensor, [batch, height*width, channels])\n",
        "    # Get the product height*width\n",
        "    n = tf.shape(tensor)[1]\n",
        "    gram = tf.matmul(tensor, tensor, transpose_a=True)\n",
        "    #gram = tf.nn.dropout(gram, 0.8)\n",
        "    #gram = tf.nn.max_pool(tf.reshape(gram,[1,channels,channels,1]),ksize = [1,2, 2,1], strides=[1, 1, 1, 1],padding= 'VALID')\n",
        "    return gram / tf.cast(n, tf.float32)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "Y4XNAnrhTL7P",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_deep_outputs(model, inputs, num_texture_layers):\n",
        "    \n",
        "    t = int(inputs.shape[0])//2\n",
        "    outputs = model(inputs)\n",
        "    color_outputs = [layer[:t] for layer in outputs[num_texture_layers:]]\n",
        "    bw_outputs = [gram_matrix(layer[t:2*t]) for layer in outputs[:num_texture_layers]]\n",
        "    nogram_outputs = [layer[t:2*t] for layer in outputs[:num_texture_layers]]\n",
        "\n",
        "    \n",
        "    return color_outputs, bw_outputs, nogram_outputs"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "t5MrJF9CVtkd",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute losses\n",
        "* get_loss computes the mean squared error of a tensor\n",
        "* compute_loss builds the graph that it iterated over\n",
        "* get_grads computes the gradients\n",
        "\n**Note** : the losses are not blended into one but are seperated across batches"
      ],
      "metadata": {
        "id": "YjhxICVylGqH",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def get_loss(tensor1, tensor2):\n",
        "    reduce_space = list(range(1,len(tensor1.shape)))\n",
        "    return tf.reduce_mean(tf.square(tensor1 - tensor2), reduce_space)"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "vi-s7e4ahjgZ",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(model, loss_weights, img_sync, const_outputs, content_image):\n",
        "    \n",
        "    content_output, texture_output, nogram_outputs = const_outputs\n",
        "    num_texture_layers = len(texture_output)\n",
        "    num_content_layers = len(content_output)\n",
        "    \n",
        "    img_sync_bw = turn_var_bw(img_sync) # Deprocess, turn to grayscale and then reprocess\n",
        "    var_inputs = tf.concat([img_sync, img_sync_bw], axis = 0)\n",
        "    img_sync_output, img_sync_bw_output, img_nogram_outputs = get_deep_outputs(model, var_inputs, num_texture_layers)\n",
        "    \n",
        "    texture_loss = 0\n",
        "    content_loss = 0\n",
        "    nogram_loss = 0\n",
        "    \n",
        "    # Accumulate texture losses from all layers\n",
        "    w_text = 1.0 / float(num_texture_layers)\n",
        "    for texture_feat, var_bw_feat in zip(texture_output, img_sync_bw_output):\n",
        "        texture_loss += w_text * get_loss(texture_feat, var_bw_feat)\n",
        "    \n",
        "    # Accumulate texture losses from all layers\n",
        "    #w_text = 1.0 / float(num_texture_layers)\n",
        "    for texture_feat, var_bw_feat in zip(nogram_outputs, img_nogram_outputs):\n",
        "        nogram_loss += w_text * get_loss(texture_feat, var_bw_feat)\n",
        "    \n",
        "    # Accumulate content losses from all layers\n",
        "    w_cont = 1.0 / float(num_content_layers)\n",
        "    for content_feat, var_feat in zip(content_output, img_sync_output):\n",
        "        content_loss += w_cont * get_loss(content_feat, var_feat)\n",
        "    \n",
        "    direct_weight, content_weight, nogram_weight, texture_weight = loss_weights\n",
        "    texture_loss *= texture_weight\n",
        "    content_loss *= content_weight\n",
        "    nogram_loss *= nogram_weight\n",
        "    \n",
        "    direct_loss = direct_weight*get_loss(img_sync, content_image)\n",
        "   \n",
        "    total_loss = texture_loss + content_loss + direct_loss+ nogram_loss\n",
        "    \n",
        "    return total_loss"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "rd4y-QxbStbL",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grads(args):\n",
        "    with tf.GradientTape() as tape: \n",
        "        loss = compute_loss(**args)\n",
        "    grads = tape.gradient(loss, args['img_sync'])\n",
        "    return grads, loss"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "S9bWgULBkdsr",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content_path = 'cathd.jpg'; texture_path = 'carbon crack.jpg'"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "Ud1lryKifLZG",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content_layers = ['block1_conv1', 'block5_conv2'] \n",
        "#content_layers = ['block5_conv2']\n",
        "\n",
        "texture_layers = ['block1_conv1',\n",
        "                  'block2_conv1','block3_conv1'\n",
        "                 #,'block4_conv1'#, 'block5_conv1'\n",
        "               ]\n"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "4_wgz6k6fHWm",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_texture_train(content_path, texture_path, layers, split,loss_weights, num_iter=1000):\n",
        "    \n",
        "    content_layers, texture_layers = layers\n",
        "    num_content_layers = len(content_layers)\n",
        "    num_texture_layers = len(texture_layers)\n",
        "    \n",
        "    model = get_model(texture_layers, content_layers) \n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "        \n",
        "    content_image = slicer(content_path, split=split)\n",
        "    content_image = load_and_process_img(content_image) # Make ready for the model\n",
        "    \n",
        "    size = Image.open(content_path).size\n",
        "    texture_image = slicer(texture_path, size = size, mode='texture', split=split)\n",
        "    texture_image = turn_bw(texture_image) # turn into grayscale\n",
        "    texture_image = load_and_process_img(texture_image) # Make ready for the model\n",
        "    \n",
        "    img_sync = tf.Variable(content_image)\n",
        "    \n",
        "    \n",
        "    const_inputs = tf.concat([content_image, texture_image], axis = 0)\n",
        "    const_outputs = get_deep_outputs(model, const_inputs, num_texture_layers)\n",
        "    \n",
        "    lr = 10\n",
        "    opt = tf.optimizers.Adam(learning_rate=lr, beta_1=0.99, epsilon=1e-1)\n",
        "    \n",
        "    args = {'model': model,'loss_weights': loss_weights,'img_sync': img_sync, \n",
        "            'const_outputs': const_outputs, 'content_image': content_image, }\n",
        "    \n",
        "    norm_means = np.array([103.939, 116.779, 123.68])\n",
        "    min_vals = -norm_means ; max_vals = 255 - norm_means\n",
        "    interval = 90; loss_track = [1]*5\n",
        "    \n",
        "    for i in range(num_iter):\n",
        "  \n",
        "        grads, loss = get_grads(args)\n",
        "        opt.apply_gradients([(grads, img_sync)])\n",
        "        clipped = tf.clip_by_value(img_sync, min_vals, max_vals)\n",
        "        img_sync.assign(clipped)\n",
        "        \n",
        "        l = loss.numpy().mean()\n",
        "        loss_track = loss_track[1:]\n",
        "        loss_track.append(l)\n",
        "        \n",
        "        perc_change = np.diff(loss_track)/np.array(loss_track)[:-1]\n",
        "        if np.absolute(perc_change).mean() < 1e-4 and i > 10:\n",
        "            lr *= 0.75\n",
        "        if lr < 5e-6:\n",
        "            break\n",
        "        if i % interval == 0:\n",
        "            plot_img = img_sync.numpy()\n",
        "            plot_img = deprocess_img(plot_img)\n",
        "            #scipy.misc.imsave('outfile.jpg', recomp(plot_img))\n",
        "            IPython.display.clear_output(wait=False)\n",
        "            IPython.display.display_png(Image.fromarray(plot_img[0]))\n",
        "            print('Iteration: {}'.format(i))        \n",
        "            print('Total loss: {:.4e}, '.format(l), 'Learning rate = ', lr)\n",
        "    \n",
        "    pics = deprocess_img(img_sync.numpy())\n",
        "    return pics\n",
        "    \n",
        "    "
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "0OpwyOVVTqOj",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texture_path = 'proco.jpg'; content_path = 'lea.jpg' # loss_weights = (8.0,3,0.3,2e-5) \n",
        "texture_path = 'carbon crack.jpg'; content_path = 'cathd.jpg'"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "VtDqsBmfJmcf",
        "colab_type": "code",
        "colab": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "img=neural_texture_train(content_path, texture_path, loss_weights = (5.0,1,0,5e-5), num_iterations=2000,\n",
        "                        split = (1,1), layers = (content_layers, texture_layers))"
      ],
      "outputs": [],
      "execution_count": 0,
      "metadata": {
        "id": "CEWxozY1m5yy",
        "colab_type": "code",
        "colab": {}
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "NeuralT.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "kernel_info": {
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}